ABSTRACT
This goes too much into low-level detail, and not enough into why this matters. It's not important for readers of the abstract to, e.g., know that there are 64 shapes, 3 feature dimensions, they are called selenoid-rich vs poor, etc. However, they do need to know a little more about why they should care. I think the following info should be in the abstract:
- previous research indicates that the informativeness of positive vs negative tests depends on the nature of the hypotheses in the space, i.e., the sparsity
- how sensitive are people to this kind of expected information value? this has not yet been studied in a conceptual / categorisation domain.
- this experiment studied that using a sorting task for a binary category where sparsity differed across conditions
- (then the final sentences after "While both request types..." are pretty good)

INTRODUCTION
Overall you did a good job here with laying out the logic of the study, but I think you could do a few more things to make it even better
- first para: link this somehow to a real task in the world or a real problem facing people. a good question to always ask is "why should my mother/brother/friend/partner care about this?" i.e., what is it actually about? so instead of leaping right into hypothesis testing, point out that in many tasks people have to seek out information and test their theories, and knowing how they do so and if they're sensitive to the nature of the environment is key to understanding how they do this. then go into the rest of it.
- in general the language is pretty tight but there are still bits that you could streamline more: e.g., "it is useful to recognise that.." (p1) [could excise], "what these measures share" --> "these measures share" and so forth
- first full para on p2, since you have the space, it might be helpful to include a figure giving the intuition of why negative evidence is uninformative when hypotheses are sparse. I'm thinking of something like slides 30 and 32 in the attached talk, or perhaps 34 and 35. obviously you would adapt them so they are appropriate and clear for the paper, and key here would be the captions, but the basic idea is to show that you can get lots of negative points and still have no idea where or what the hypothesis is, but only a few positive ones tell you a lot.
- in general the first part of the intro talks about confirmation bias and then you shift to talking about positive test bias. they are subtly different, and what you've been talking about is positive test bias - asking questions that will give a YES if your currently preferred candidate hypothesis is true. (as I understand it PTS is not always confirmation bias because positive tests actually do let you falsify your hypotheses (if they predict a positive and you get a negative) and sometimes confirmation bias is interpreted more broadly, to mean that you are using tests that do not falsify your hypothesis, or are deliberately ignoring falsifying information. in any event, best to avoid that entire can of worms and just talk about positive tests throughout, as you'll notice we did in our PsychRev paper)
- could probably do with a bit of elaboration of the paragraph beginning "one potential problem.." because that really motivates this work. basically point out that since Hendrickson et al is so visual, the visual system could have been doing a lot of the work, but of course in the real world most situations where you might need to seek out information are not visual

METHOD
- naming the conditions 25%, 50%, and 75% becomes a bit confusing with all the percentiles later (in the results) floating around. would suggest setting it off graphically using e.g. small caps and also naming them something like SPARSE, EVEN, and NON-SPARSE. also note here that SPARSE and NON_SPARSE are just flips of one another, and thus people might interpret as the same, and you return to this issue in the discussion -- just because it's something that people will pick up on and you don't want to leave them hanging until then
- the para after "procedure" is long and hard to read. put a break at "once a sort"... also, you might describe the score in more detail, e.g., report what a score of chance would be and a maximum score.
- talk a little bit more about how the practice trial required a plausible sort. you just mean that it had to have the appropriate numbers in each category, right? if so, say that. main thing is we don't want a reviewer to think that we caused our results by "training" participants in the practice trial to sort "the right way" or something. also note that the practice trial was not analysed.
- when you say the stimuli varied in colour list the colours
- the sentence starting p3 "the true selenoid status..." is good but hard to understand. use another sentence to give an example, e.g., for instance, one participant on one trial in the SPARSE condition might see plankton in which the selenoid-rich ones had four arms and the selenoid-poor ones had one, two, or three. also note that which rules were used on which trials was completely randomised for each participant.
- do not refer to conditions as 25%:75% split or whatever. even if you don't use word labels like I suggest, that is massively confusing - were you referring to the 25%, 75%, or both? I think if you use the labels you don't need the sentence on page 3 starting "selenoid-rich plankton could be 25% (sparse target)..." and so forth. And the next sentence can read "In the SPARSE and NON-SPARSE conditions, [blah blah]" and so forth.

RESULTS
- if there is room, I think a figure showing the score distribution would be good, rather than just saying it's bimodal. if not, that's fine, but again please use the word labels, I found that paragraph hard to read.
- when reporting average score and number of plankton correctly sorted, remind people what chance and maximum score are, and how many total plankton there are. they won't remember and this is hard to interpret without that info.
- when you say "scores and number of label requests were similar" did you actually do the stats? if so report it as "not significantly different". if not, could you do the stats?
- "To account for the fact..." sentence p3 is long and unwieldy. Separate into two, remove excess words.
- no need to report the actual numbers for mean proportion of requests - this is shown in Figure 1. I would collapse several of the sentences on p3 starting with "Mean proportion of.." and going through the stats and say something like "Figure 1 shows that people were more likely to make positive requests in sparser conditions (F(2,359) = 9.581, p<0.001)." Way simpler and also clearer.
- you also use way more words than you need describing the post-hoc tests, but don't report the actual stats. Just say "Post-hod tests showed a significant difference between requests in the SPARSE and NON-SPARSE condition (STATS), as well as the EVEN and NON-SPARSE condition (STATS)."
- Figure 3: don't call it "percent rich" in the title, call it sparsity condition or something. also the columns should read SPARSE, EVEN, and NON-SPARSE. i also do think the mean tends to get obscured among these larger dots. can you make it a thicker line, maybe not going across the entire column (so it doesn't appear to split the column into bits, same with the error bars). also, why are some dots darker than others? are those actually showing lots of docs on top of each other? looks weird.
- motivate the paragraph beginnning "the difference in means", and split that sentence to make it easier to read. also combine it with the next paragraph. e.g. "As Figure 3 shows, these results do not appear to reflect a large-scale shift in requests for all individuals from condition to condition. Rather, in all conditions, responses tended to cluster at the special values of 1 (all positive), 0 (all negative), and 0.5 (even). The proportion of people choosing each strategy is what appears to shift between conditions. We can test whether this is truly occurring by categorizing responses by request strategy, as in Figure 4. An 'Even' strategy... [blah continue to define as you have]. Again I dislike all the many single quotes, I find it quite hard to read, prefer setting it off typographically, maybe with italic or someething (in the text)
- you don't need to report the actual percentages of changes from condition to condition when talking about Figure 4 - people can get that from the figure. what you say is fine, just don't bother including the percentages. also, you can test whether these differences are significant using a Chi-Square test on the actual numbers (not the proportions). please do, it will make it much stronger.
- paragraph beginning "All strategies.." should end with the take-home point: this shows that although the majority of people in all conditions preferred an even split, there was some sensitivity to sparsity: people in the SPARSE condition were more likely to prefer positive test strategies, and in the NON-SPARSE condition were more likely to disprefer them. or something like that. always remind people what the point is and why they should care.
- i think if you do a chi-square test as suggested above you don't need to do the test you describe in the last para of the results (which, if you do include it, put it abefore the para starting "in the 25%:75% split conditions"...). but anyway I don't think you need it, I think chi-square is more sensitive because it will be on all of the data and not just the prefers-positive stategy (which I noticed you at later points are not putting into single quotes - be consistent throughout).
- para beginining "in the 25%:75% split conditions,..." change the order of presentation. the more general question is whether these results were driven by the people who scored highly (in all conditions, not just those, although it's even more obvious there). so lead off with that question, and then head into "to examine..." (that sentence is long and unwieldy too)
- when you report "both higher-scoring trials and lower-scoring trials showed the same clustering pattern" it would be awesome to show that in a figure. you have the space and this important point will be lost otherwise. show it in a separate figure. also, did you run stats on this? report them.
- sentence starting "collapsing across conditions", this is actually a separate point and should be a separate paragraph. it should also be more well-motivated... till now you're looking at differences in relative preference, but overall did people tend to prefer one or the other? indeed, a slight preference for positive (then report stats, all of them (I assume you used a t-test? include t, df, etc)).

DISCUSSION
- you should point out that although people are sensitive broadly speaking, still the majority of people prefer an even strategy, and it's not a large effect. this may be because [insert hypotheses here, e.g., not paying close attention / wanting to get out early; accessibility of a heuristic that leads to that style, etc etc.]
- also point out that SPARSE and NON-SPARSE conditions are flips of one another and people's behaviour was also flipped, so they weren't super influenced by the frame (i.e., one might have expected that they would always ask for selenoid-rich ones because that's what the cover story framed it as, but no, they actually were sensitive to the informativeness).
- re: dropout rate, i don't think you should report nor should you be concerned about the number of people who didn't even attempt. this is never reported nor tracked so we have no sense that it's extreme, and my hunch is that you would find typical rates for all MT experiments. go ahead and report attempts and completions, etc.
- "a number of features of the presentation [blah] p5 should start its own paragraph. 
- need a conclusion sentence. i would start a new para with "further work is required" and then end with some sentence saying something like "regardless of how this is achieved, this research is the first to show that people are sensitivity to the overall nature of the hypotheses -- i.e., their sparsity -- when seeking out information in a conceptual domain." (or something like that, it's not ideal, but you get the point)


MORE MINOR 
- p1 "due to Klayman and Ha (Klayman & Ha, 1987)" --> should be "due to Klayman & Ha (1987)" - I think you can use \citeA or something like that to get it to do that
- p1 "confirmatory test - in the sense that ..." is rather awkward. maybe "confirmatory tests, which are consistent with [blah blah], can often be very informative."
- try where possible to cite things at the end of the sentence; it's far more readable. e.g. last para of p1 "showing the value of confirmatory evidence (BLAH) do not imply.." just put the citations at the end, it's still interpretable, and way easier to read. look for this and change it throughout the paper
- top of p2, it's hard to read with all the categories in single quotes. a common way to do this is small caps (which is \sc in latex). e.g. "in the domain of living species, the category DOGS is sparse, while AEROBIC ORGANISM is not.."
- top of p2 "a non-sparse" --> "not sparse"
- refer to Hendrickson et al, not Hendrickson. ask him for the working title, i think he has one.
- p2 "in this task, all hypotheses have the same sparsity" --> this was confusing and also I think unnecessary - the key point is the next sentence
- in general spell out numbers that are ten or less, e.g., in the method etc.
- p3 "highly successful, defined as [BLAH]" --> "highly successful: on 18% of all trials, people required fewer than six labels to sort at least 93% correctly."
